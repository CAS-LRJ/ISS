{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ISS.algorithms.perception.detection_2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Python_project\\ISS\\examples\\test_detection_2d.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# from ISS.algorithms.utils.dataexchange.detection_2d import Detection2DOutput, Detection2DInput\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mISS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mperception\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdetection_2d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretina\u001b[39;00m \u001b[39mimport\u001b[39;00m Retina\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mISS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mperception\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdetection_2d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myolov3\u001b[39;00m \u001b[39mimport\u001b[39;00m YoloV3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mISS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msensors\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcamera\u001b[39;00m \u001b[39mimport\u001b[39;00m Camera\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ISS.algorithms.perception.detection_2d'"
     ]
    }
   ],
   "source": [
    "from ISS.algorithms.utils.dataexchange.detection_2d import Detection2DOutput, Detection2DInput\n",
    "from ISS.algorithms.perception.detection_2d.retina import Retina\n",
    "from ISS.algorithms.perception.detection_2d.yolov3 import YoloV3\n",
    "from ISS.algorithms.sensors.camera import Camera\n",
    "import os\n",
    "from beamngpy import BeamNGpy, Scenario, Vehicle\n",
    "\n",
    "USERPATH = fr'{os.getenv(\"LOCALAPPDATA\")}/BeamNG.tech'   \n",
    "beamng = BeamNGpy('localhost', 64256, user=USERPATH)\n",
    "bng = beamng.open(launch=True, extensions=['util/roadData'])\n",
    "scenario = Scenario('italy', 'Map Mod Test')\n",
    "vehicle = Vehicle('ego_vehicle', model='vivace', license='AI', extensions=['mapPath'], partConfig='vehicles/vivace/tograc_qE_Unbreakable.pc')\n",
    "scenario.add_vehicle(vehicle, pos=(-709, -1342, 141), rot_quat=(0, 0, -0.82, 0.55))\n",
    "scenario.make(bng)\n",
    "bng.settings.set_deterministic(60) # Set simulator to 60hz temporal resolution\n",
    "bng.scenario.load(scenario)\n",
    "bng.scenario.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YoloV3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Python_project\\ISS\\examples\\test_detection_2d.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model = Retina('../resources/models/detection_2d/retinanet.pt')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m YoloV3(\u001b[39m'\u001b[39m\u001b[39m../resources/models/detection_2d/yolov3.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m camera \u001b[39m=\u001b[39m Camera()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python_project/ISS/examples/test_detection_2d.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m camera\u001b[39m.\u001b[39mfrom_beamng(bng, vehicle)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YoloV3' is not defined"
     ]
    }
   ],
   "source": [
    "# model = Retina('../resources/models/detection_2d/retinanet.pt')\n",
    "model = YoloV3('../resources/models/detection_2d/yolov3.pt')\n",
    "camera = Camera()\n",
    "camera.from_beamng(bng, vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9552016258239746\n",
      "0.5732579231262207\n",
      "0.5671658515930176\n",
      "0.6219182014465332\n",
      "0.5434145927429199\n",
      "0.5111427307128906\n",
      "0.563483715057373\n",
      "0.4927375316619873\n",
      "0.4984734058380127\n",
      "0.5393669605255127\n",
      "0.598318338394165\n",
      "0.4710988998413086\n",
      "0.5470335483551025\n",
      "0.6181483268737793\n",
      "0.5272719860076904\n",
      "0.4283134937286377\n",
      "0.5481081008911133\n",
      "0.5066413879394531\n",
      "0.5174412727355957\n",
      "0.6112782955169678\n",
      "0.5222985744476318\n",
      "0.5224776268005371\n",
      "0.4723043441772461\n",
      "0.6037342548370361\n",
      "0.4882168769836426\n",
      "0.5125982761383057\n",
      "0.6033046245574951\n",
      "0.5849883556365967\n",
      "0.5880298614501953\n",
      "0.7016620635986328\n",
      "0.46344590187072754\n",
      "0.46680188179016113\n",
      "0.7510039806365967\n",
      "0.6863894462585449\n",
      "0.7410731315612793\n",
      "0.7031943798065186\n",
      "0.767920970916748\n",
      "0.7288322448730469\n",
      "0.7059476375579834\n",
      "0.8487386703491211\n",
      "0.6796176433563232\n",
      "0.7859377861022949\n",
      "0.8184142112731934\n",
      "0.7391800880432129\n",
      "0.7170495986938477\n",
      "0.7926633358001709\n",
      "0.6639978885650635\n",
      "0.7555437088012695\n",
      "0.7581448554992676\n",
      "0.8104674816131592\n",
      "0.7498936653137207\n",
      "0.710310697555542\n",
      "0.9310669898986816\n",
      "0.7615084648132324\n",
      "0.7933821678161621\n",
      "0.7936856746673584\n",
      "0.6287906169891357\n",
      "0.6173229217529297\n",
      "0.905031681060791\n",
      "0.8591210842132568\n",
      "0.7864243984222412\n",
      "0.8963024616241455\n",
      "0.830608606338501\n",
      "0.8785338401794434\n",
      "0.8773102760314941\n",
      "0.9443254470825195\n",
      "0.8264608383178711\n",
      "0.8719770908355713\n",
      "0.9238893985748291\n",
      "0.9253561496734619\n",
      "0.9085490703582764\n",
      "0.7215235233306885\n",
      "0.48754000663757324\n",
      "0.506014347076416\n",
      "0.935556173324585\n",
      "0.9848799705505371\n",
      "0.981177568435669\n",
      "0.8944482803344727\n",
      "0.7883176803588867\n",
      "0.7890141010284424\n",
      "0.7007362842559814\n",
      "0.8657572269439697\n",
      "0.757702112197876\n",
      "0.7461121082305908\n",
      "0.8367202281951904\n",
      "0.6886682510375977\n",
      "0.9232900142669678\n",
      "0.8866033554077148\n",
      "0.7822263240814209\n",
      "0.7452902793884277\n",
      "0.8294522762298584\n",
      "0.7582511901855469\n",
      "0.7624850273132324\n",
      "0.7393131256103516\n",
      "0.7910127639770508\n",
      "0.8377418518066406\n",
      "0.7854297161102295\n",
      "0.9129762649536133\n",
      "0.7491974830627441\n",
      "0.7843990325927734\n",
      "0.8573567867279053\n",
      "0.7413392066955566\n",
      "0.715583324432373\n",
      "0.8238444328308105\n",
      "0.6986758708953857\n",
      "0.7606310844421387\n",
      "0.8274562358856201\n",
      "0.7431137561798096\n",
      "0.78336501121521\n",
      "0.8681085109710693\n",
      "0.955925464630127\n",
      "0.888702392578125\n",
      "0.776059627532959\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# det_in.resize_image.show()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(model.detect(det_in))\u001b[39;00m\n\u001b[0;32m     19\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 20\u001b[0m model_out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdetect(det_in)\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart)\n\u001b[0;32m     22\u001b[0m det_out\u001b[39m.\u001b[39mfrom_output(det_in, model_out)    \n",
      "File \u001b[1;32mD:\\Documents\\ISS\\ISS\\algorithms\\perception\\detection_2d\\base.py:14\u001b[0m, in \u001b[0;36mdetector_2d_base.detect\u001b[1;34m(self, detection_2d_input)\u001b[0m\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m to_tensor(detection_2d_input\u001b[39m.\u001b[39mresize_image)\n\u001b[0;32m     13\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> 14\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torch\\fx\\graph_module.py:658\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torch\\fx\\graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[1;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m<eval_with_key>.1:675\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, input_1)\u001b[0m\n\u001b[0;32m    673\u001b[0m transpose_3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTranspose_3(reshape_20)\n\u001b[0;32m    674\u001b[0m constant_195 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mConstant_195()\n\u001b[1;32m--> 675\u001b[0m non_max_suppression_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mNonMaxSuppression_0(reshape_18, transpose_3, constant_195, constant_178, constant_179);  constant_195 \u001b[39m=\u001b[39m constant_178 \u001b[39m=\u001b[39m constant_179 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    676\u001b[0m gather_36 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGather_36(non_max_suppression_0, constant_5);  constant_5 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    677\u001b[0m gather_37 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGather_37(non_max_suppression_0, constant_0);  constant_0 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\onnx2torch\\node_converters\\nms.py:61\u001b[0m, in \u001b[0;36mOnnxNonMaxSuppression.forward\u001b[1;34m(self, boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\u001b[0m\n\u001b[0;32m     49\u001b[0m     onnx_attrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_onnx_attrs(opset_version\u001b[39m=\u001b[39mget_onnx_version())\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m DefaultExportToOnnx\u001b[39m.\u001b[39mexport(\n\u001b[0;32m     51\u001b[0m         forward_lambda,\n\u001b[0;32m     52\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mNonMaxSuppression\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m         onnx_attrs,\n\u001b[0;32m     59\u001b[0m     )\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m forward_lambda()\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\onnx2torch\\node_converters\\nms.py:39\u001b[0m, in \u001b[0;36mOnnxNonMaxSuppression.forward.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(  \u001b[39m# pylint: disable=missing-function-docstring\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     33\u001b[0m     boxes: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     score_threshold: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> 39\u001b[0m     forward_lambda \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nms(boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mis_in_onnx_export():\n\u001b[0;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m max_output_boxes_per_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\onnx2torch\\node_converters\\nms.py:94\u001b[0m, in \u001b[0;36mOnnxNonMaxSuppression._nms\u001b[1;34m(self, boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_center_point_box:\n\u001b[0;32m     88\u001b[0m     filtered_batch_boxes \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mbox_convert(\n\u001b[0;32m     89\u001b[0m         filtered_batch_boxes,\n\u001b[0;32m     90\u001b[0m         in_fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcxcywh\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     91\u001b[0m         out_fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mxyxy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     92\u001b[0m     )\n\u001b[1;32m---> 94\u001b[0m nms_indexes \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mnms(\n\u001b[0;32m     95\u001b[0m     boxes\u001b[39m=\u001b[39;49mfiltered_batch_boxes,\n\u001b[0;32m     96\u001b[0m     scores\u001b[39m=\u001b[39;49mclass_scores[confidence_indexes],\n\u001b[0;32m     97\u001b[0m     iou_threshold\u001b[39m=\u001b[39;49miou_threshold,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m num_boxes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_output_boxes_per_class, nms_indexes\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[0;32m    100\u001b[0m nms_indexes \u001b[39m=\u001b[39m nms_indexes[:num_boxes]\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorchvision\u001b[39m.\u001b[39;49mnms(boxes, scores, iou_threshold)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\beamng\\lib\\site-packages\\torch\\_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    438\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    441\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard','sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator,book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "det_in = Detection2DInput(resize=320, stride=320)\n",
    "det_out = Detection2DOutput(names, [], 0.5, '../logs/2d_det_demo.mp4', True, True)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    det_in.from_camera(camera)    \n",
    "    # det_in.resize_image.show()\n",
    "    # print(model.detect(det_in))\n",
    "    start = time.time()\n",
    "    model_out = model.detect(det_in)\n",
    "    print(time.time()-start)\n",
    "    det_out.from_output(det_in, model_out)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beamng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
